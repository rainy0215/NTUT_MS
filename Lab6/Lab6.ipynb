{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "Lab6.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqmhX_OcZdXO"
      },
      "source": [
        "# TensorFlow進階技巧"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3dfJWHzZdXO"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab6.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab6.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmsn0XNkZdXP"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvOHFXfaZdXP"
      },
      "source": [
        "## Custom Layers\n",
        "透過繼承`tf.keras.layers.Layer`類別，來輕鬆創建字定義的網路層。\n",
        "\n",
        "你可以到https://www.tensorflow.org/api_docs/python/tf/keras/layers 官方API察看更多的網路層。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWEBBWYzZdXQ"
      },
      "source": [
        "Example: 簡單的客自化Convolutional layers。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPQk292lZdXQ"
      },
      "source": [
        "class CustomConv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, strides=(1, 1), padding=\"VALID\", **kwargs):\n",
        "        super(CustomConv2D, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = (1, *strides, 1)\n",
        "        self.padding = padding\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        input_dim = input_shape[-1]\n",
        "        # 創建卷積的權重值(weights)\n",
        "        self.w = self.add_weight(name='kernel', \n",
        "                                 shape=(kernel_h, kernel_w, input_dim, self.filters),\n",
        "                                 initializer='glorot_uniform',  # 設定初始化方法\n",
        "                                 trainable=True)  # 設定這個權重是否能夠訓練(更動)\n",
        "        # 創建卷積的偏差值(bias)\n",
        "        self.b = self.add_weight(name='bias', \n",
        "                                 shape=(self.filters,),\n",
        "                                 initializer='zeros',  # 設定初始化方法\n",
        "                                 trainable=True)  # 設定這個權重是否能夠訓練(更動)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.nn.conv2d(inputs, self.w, self.strides, padding=self.padding) # 卷積運算\n",
        "        x = tf.nn.bias_add(x, self.b)  # 加上偏差值\n",
        "        x = tf.nn.relu(x)  # 激活函數\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2wRY94SZdXR"
      },
      "source": [
        "## Custom Loss\n",
        "\n",
        "在設計進階的研究方法或更深入解決問題時，TensorFlow官方文件所提供的損失函數，通常不夠使用，這時候你就必須自己定義損失函數，實作自己設計的損失函數。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNoD0KTwZdXS"
      },
      "source": [
        "Example: 簡單的客自化Crossentropy Loss。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oH4e2m0TZdXS"
      },
      "source": [
        "def custom_categorical_crossentropy(y_true, y_pred):\n",
        "    # x = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_pred), reduction_indices=[1]))\n",
        "    x = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze-WJPj6ZdXS"
      },
      "source": [
        "## Custom Metrics\n",
        "\n",
        "如果你需要的指標函數官方API並沒有提供，你可以通過繼承`tf.keras.metrics.Metric`類別，來輕鬆創建自定義的指標函數。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTEsZxwQZdXT"
      },
      "source": [
        "Example: 計算多少個樣本是正確分類的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ymeQp2CZdXU"
      },
      "source": [
        "class CustomCategoricalAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='custom_catrgorical_accuracy', **kwargs):\n",
        "        super(CustomCategoricalAccuracy, self).__init__(name=name, **kwargs)\n",
        "        # 記錄正確預測的數量\n",
        "        self.correct = self.add_weight('correct_numbers', initializer='zeros')\n",
        "        # 記錄全部資料的量數\n",
        "        self.total = self.add_weight('total_numbers', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # 輸入答案為One-hot編碼，所以取最大的數值為答案\n",
        "        y_true = tf.argmax(y_true, axis=-1)\n",
        "        # 取預測輸出最大的數值為預測結果\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        # 比較預測結果是否正確，正確會返回True(正確)，錯誤會返回False(錯誤)\n",
        "        values = tf.equal(y_true, y_pred)\n",
        "        # 轉為浮點數True(正確)=1.0，False(錯誤)=0.0\n",
        "        values = tf.cast(values, tf.float32)\n",
        "        # 將values所有數值相加就會等於正確預測的總數\n",
        "        values_sum = tf.reduce_sum(values)\n",
        "        # 計算這個Batch的資料數量\n",
        "        num_values = tf.cast(tf.size(values), tf.float32)\n",
        "        self.correct.assign_add(values_sum)  # 更新正確預測的總數\n",
        "        self.total.assign_add(num_values)  # 更新資料量的總數\n",
        "\n",
        "    def result(self):\n",
        "        # 計算準確率\n",
        "        return tf.math.divide_no_nan(self.correct, self.total)\n",
        "\n",
        "    def reset_states(self):\n",
        "        # 每一次Epoch結束後會重新初始化變數\n",
        "        self.correct.assign(0.)\n",
        "        self.total.assign(0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb_lwT-7ZdXU"
      },
      "source": [
        "## Custom Callbacks\n",
        "\n",
        "如果你需要的監控或執行的操作官方的Callbacks函數沒有提供，你可以通過繼承`tf.keras.callbacks.Callback`類別，來輕鬆創建字定義的Callbacks函數。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHzv82PLZdXV"
      },
      "source": [
        "Example: 紀錄每一個batch的loss值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcM6exvZdXV"
      },
      "source": [
        "class SaveModel(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, weights_file, monitor='loss', mode='min', save_weights_only=False):\n",
        "        super(SaveModel, self).__init__()\n",
        "        self.weights_file = weights_file\n",
        "        self.monitor = monitor\n",
        "        self.mode = mode\n",
        "        self.save_weights_only = save_weights_only\n",
        "        if mode == 'min':\n",
        "            self.best = np.Inf\n",
        "        else:\n",
        "            self.best = -np.Inf\n",
        "        \n",
        "    def save_model(self):\n",
        "        if self.save_weights_only:\n",
        "            self.model.save_weights(self.weights_file)\n",
        "        else:\n",
        "            self.model.save(self.weights_file)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        monitor_value = logs.get(self.monitor)\n",
        "        if self.mode == 'min' and monitor_value < self.best:\n",
        "            self.save_model()\n",
        "            self.best = monitor_value\n",
        "        elif self.mode == 'max' and monitor_value > self.best:\n",
        "            self.save_model()\n",
        "            self.best = monitor_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3e438g2ZdXV"
      },
      "source": [
        "# 實驗：比較Keras高階API和客製化API兩種網路訓練的結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxjIz3-pZdXW"
      },
      "source": [
        "### Import 必要套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlLkyYm5ZdXW"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "from preprocessing import parse_aug_fn, parse_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ax1N3HgZdXX"
      },
      "source": [
        "### Cifar 10\n",
        "載入Cifar10數據集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2vgdJkLZdXX"
      },
      "source": [
        "# 將train Data重新分成9:1等分，分別分給train data, valid data\n",
        "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
        "# 取得訓練數據，並順便讀取data的資訊\n",
        "train_data, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
        "# 取得驗證數據\n",
        "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
        "# 取得測試數據\n",
        "test_data = tfds.load(\"cifar10\", split=tfds.Split.TEST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZTkjrNFZdXX"
      },
      "source": [
        "### Dataset 設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o65wtPbXZdXX"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
        "batch_size = 64  # 批次大小\n",
        "train_num = int(info.splits['train'].num_examples / 10) * 9  # 訓練資料數量\n",
        "\n",
        "train_data = train_data.shuffle(train_num)  # 打散資料集\n",
        "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
        "train_data = train_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "test_data = test_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxqb0mQUZdXY"
      },
      "source": [
        "### 1. 使用Keras高階API訓練網路模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05m4BOS3ZdXY"
      },
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(256, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
        "model_1 = keras.Model(inputs, outputs, name='model-1')\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1skHKFrZdXZ"
      },
      "source": [
        "建立Callback function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzdTupguZdXZ"
      },
      "source": [
        "# 儲存訓練記錄檔\n",
        "logs_dirs = 'lab6-logs'\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir='lab6-logs')\n",
        "\n",
        "# 紀錄每一個batch的Loss值變化\n",
        "model_dirs = logs_dirs + '/models'\n",
        "os.makedirs(model_dirs, exist_ok=True)\n",
        "save_model = tf.keras.callbacks.ModelCheckpoint(model_dirs + '/save.h5', \n",
        "                                                monitor='val_catrgorical_accuracy', \n",
        "                                                mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJYg8a2uZdXZ"
      },
      "source": [
        "設定訓練使用的優化器、客自化損失函數和客自化指標函數："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0kTNIH8ZdXZ"
      },
      "source": [
        "# 設定訓練使用的優化器、損失函數和指標函數\n",
        "model_1.compile(keras.optimizers.Adam(), \n",
        "                loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "                metrics=[keras.metrics.CategoricalAccuracy()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NUP__X91ZdXZ"
      },
      "source": [
        "# 訓練網路模型\n",
        "model_1.fit(train_data,\n",
        "            epochs=100, \n",
        "            validation_data=valid_data,\n",
        "            callbacks=[model_cbk, save_model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjEb8_cCZdXa"
      },
      "source": [
        "### 2. 使用客自化API訓練網路模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2LkBdnIZdXa"
      },
      "source": [
        "- Custom Layer：將原本的Conv2d改成CustomConv2D。\n",
        "- Custom Loss：將原本的CategoricalCrossentropy改成custom_loss。\n",
        "- Custom Metrics：加入一個新的指標函數CatgoricalTruePositives。\n",
        "- Custom Callbacks：紀錄每一個batch的Loss值變化。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1sra36WZdXa"
      },
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = CustomConv2D(64, (3, 3))(inputs)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = CustomConv2D(128, (3, 3))(x)\n",
        "x = CustomConv2D(256, (3, 3))(x)\n",
        "x = CustomConv2D(128, (3, 3))(x)\n",
        "x = CustomConv2D(64, (3, 3))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
        "model_2 = keras.Model(inputs, outputs, name='model-2')\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpGNcjfyZdXa"
      },
      "source": [
        "# 儲存訓練記錄檔\n",
        "logs_dirs = 'lab6-logs'\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir='lab6-logs')\n",
        "\n",
        "# 紀錄每一個batch的Loss值變化\n",
        "model_dirs = logs_dirs + '/models'\n",
        "os.makedirs(model_dirs, exist_ok=True)\n",
        "custom_save_model = SaveModel(model_dirs + '/custom_save.h5', \n",
        "                              monitor='val_custom_catrgorical_accuracy', \n",
        "                              mode='max', \n",
        "                              save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxWoUFJuZdXb"
      },
      "source": [
        "# 設定訓練使用的優化器、損失函數和指標函數\n",
        "model_2.compile(keras.optimizers.Adam(), \n",
        "           loss=custom_categorical_crossentropy, \n",
        "           metrics=[CustomCategoricalAccuracy()])\n",
        "\n",
        "# 訓練網路模型\n",
        "model_2.fit(train_data,\n",
        "            epochs=100, \n",
        "            validation_data=valid_data,\n",
        "            callbacks=[model_cbk, custom_save_model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-CFvezNZdXb"
      },
      "source": [
        "### 比較兩種方法的訓練結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtycgTFJZdXc"
      },
      "source": [
        "載入兩種方法的模型權重："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrOBqRQHZdXc"
      },
      "source": [
        "model_1.load_weights(model_dirs+'/save.h5')\n",
        "model_2.load_weights(model_dirs+'/custom_save.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uauOvH88ZdXc"
      },
      "source": [
        "驗證網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1N--FYiZdXc"
      },
      "source": [
        "loss_1, acc_1 = model_1.evaluate(test_data)\n",
        "loss_2, acc_2 = model_2.evaluate(test_data)\n",
        "loss = [loss_1, loss_2]  \n",
        "acc = [acc_1, acc_2]\n",
        "dict = {\"Loss\": loss, \"Accuracy\": acc}\n",
        "pd.DataFrame(dict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}